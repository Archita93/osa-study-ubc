{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98cb5b1",
   "metadata": {},
   "source": [
    "- https://arxiv.org/abs/1802.00308; https://medium.com/intuition/deep-recurrent-neural-networks-for-electroencephalography-analysis-7c428c50f038\n",
    "\n",
    "- https://github.com/Khalizo/Deep-Learning-Detection-Of-EEG-Based-Attention/tree/master\n",
    "\n",
    "- https://github.com/SuperBruceJia/EEG-DL\n",
    "\n",
    "- https://pmc.ncbi.nlm.nih.gov/articles/PMC10372445/\n",
    "\n",
    "- https://www.sciencedirect.com/science/article/pii/B9780128240540000095:\n",
    "\n",
    "    More channels; C;ass imbalance; CNN, Hybrid R-CNN, DT, NN, SVM, KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b77a82e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10261fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/highAHI/OSAA10002_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "baba075e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'-1': np.int64(0), 'M': np.int64(1), 'P': np.int64(2), 'PP': np.int64(3)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label_encoded'] = le.fit_transform(df['Hypopnea_Label_Encode'])\n",
    "\n",
    "# Check mapping:\n",
    "print(dict(zip(le.classes_, le.transform(le.classes_))))\n",
    "# Example output:\n",
    "# {'-1': 0, 'M': 1, 'P': 2, 'PP': 3}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfa33ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hypopnea_Label_Encode\n",
       "-1    2519\n",
       "P       51\n",
       "M       51\n",
       "PP      46\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Hypopnea_Label_Encode.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91165de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mini_Epoch_Index</th>\n",
       "      <th>Sleeping_stage</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Sigma</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Gamma</th>\n",
       "      <th>TotalAbsPow</th>\n",
       "      <th>Hypopnea_Label_Encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.353299</td>\n",
       "      <td>0.084716</td>\n",
       "      <td>0.290772</td>\n",
       "      <td>0.048878</td>\n",
       "      <td>0.125810</td>\n",
       "      <td>0.096525</td>\n",
       "      <td>8.252734e-11</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.350105</td>\n",
       "      <td>0.054575</td>\n",
       "      <td>0.354590</td>\n",
       "      <td>0.040920</td>\n",
       "      <td>0.121198</td>\n",
       "      <td>0.078611</td>\n",
       "      <td>6.210068e-11</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.247155</td>\n",
       "      <td>0.066444</td>\n",
       "      <td>0.499360</td>\n",
       "      <td>0.027917</td>\n",
       "      <td>0.093214</td>\n",
       "      <td>0.065909</td>\n",
       "      <td>6.417000e-11</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.354059</td>\n",
       "      <td>0.105969</td>\n",
       "      <td>0.223098</td>\n",
       "      <td>0.069373</td>\n",
       "      <td>0.162833</td>\n",
       "      <td>0.084667</td>\n",
       "      <td>4.133262e-11</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.118186</td>\n",
       "      <td>0.041903</td>\n",
       "      <td>0.747283</td>\n",
       "      <td>0.015630</td>\n",
       "      <td>0.052638</td>\n",
       "      <td>0.024361</td>\n",
       "      <td>1.324671e-10</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2662</th>\n",
       "      <td>2663</td>\n",
       "      <td>0</td>\n",
       "      <td>0.584954</td>\n",
       "      <td>0.097088</td>\n",
       "      <td>0.032402</td>\n",
       "      <td>0.082907</td>\n",
       "      <td>0.118319</td>\n",
       "      <td>0.084329</td>\n",
       "      <td>8.745815e-11</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>2664</td>\n",
       "      <td>0</td>\n",
       "      <td>0.693394</td>\n",
       "      <td>0.046640</td>\n",
       "      <td>0.019170</td>\n",
       "      <td>0.032831</td>\n",
       "      <td>0.113093</td>\n",
       "      <td>0.094872</td>\n",
       "      <td>2.506265e-10</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>2665</td>\n",
       "      <td>0</td>\n",
       "      <td>0.549748</td>\n",
       "      <td>0.107757</td>\n",
       "      <td>0.029323</td>\n",
       "      <td>0.039583</td>\n",
       "      <td>0.146618</td>\n",
       "      <td>0.126971</td>\n",
       "      <td>1.005049e-10</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2665</th>\n",
       "      <td>2666</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.593619</td>\n",
       "      <td>0.078667</td>\n",
       "      <td>0.063104</td>\n",
       "      <td>0.031854</td>\n",
       "      <td>0.125769</td>\n",
       "      <td>0.106987</td>\n",
       "      <td>1.174124e-10</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>2667</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.551080</td>\n",
       "      <td>0.102037</td>\n",
       "      <td>0.044186</td>\n",
       "      <td>0.042133</td>\n",
       "      <td>0.139547</td>\n",
       "      <td>0.121018</td>\n",
       "      <td>1.064156e-10</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2667 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Mini_Epoch_Index  Sleeping_stage     Delta     Theta     Alpha  \\\n",
       "0                    1               0  0.353299  0.084716  0.290772   \n",
       "1                    2              -1  0.350105  0.054575  0.354590   \n",
       "2                    3              -1  0.247155  0.066444  0.499360   \n",
       "3                    4               0  0.354059  0.105969  0.223098   \n",
       "4                    5               0  0.118186  0.041903  0.747283   \n",
       "...                ...             ...       ...       ...       ...   \n",
       "2662              2663               0  0.584954  0.097088  0.032402   \n",
       "2663              2664               0  0.693394  0.046640  0.019170   \n",
       "2664              2665               0  0.549748  0.107757  0.029323   \n",
       "2665              2666              -1  0.593619  0.078667  0.063104   \n",
       "2666              2667              -1  0.551080  0.102037  0.044186   \n",
       "\n",
       "         Sigma      Beta     Gamma   TotalAbsPow Hypopnea_Label_Encode  \n",
       "0     0.048878  0.125810  0.096525  8.252734e-11                    -1  \n",
       "1     0.040920  0.121198  0.078611  6.210068e-11                    -1  \n",
       "2     0.027917  0.093214  0.065909  6.417000e-11                    -1  \n",
       "3     0.069373  0.162833  0.084667  4.133262e-11                    -1  \n",
       "4     0.015630  0.052638  0.024361  1.324671e-10                    -1  \n",
       "...        ...       ...       ...           ...                   ...  \n",
       "2662  0.082907  0.118319  0.084329  8.745815e-11                    -1  \n",
       "2663  0.032831  0.113093  0.094872  2.506265e-10                    -1  \n",
       "2664  0.039583  0.146618  0.126971  1.005049e-10                    -1  \n",
       "2665  0.031854  0.125769  0.106987  1.174124e-10                    -1  \n",
       "2666  0.042133  0.139547  0.121018  1.064156e-10                    -1  \n",
       "\n",
       "[2667 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db2e2297",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "features = [\"Sleeping_stage\",\"Delta\",\"Theta\",\"Alpha\",\"Sigma\",\"Beta\",\"Gamma\",\"TotalAbsPow\"]\n",
    "\n",
    "for i in range(2, len(df)):\n",
    "    seq = df.iloc[i-2:i][features].values\n",
    "    label = df.iloc[i]['label_encoded']\n",
    "    \n",
    "    X.append(seq)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092c407c",
   "metadata": {},
   "source": [
    "### does pp, p, m, -1 have any statistical differences, - median, mean of delta, alpha, beta, gamma etc (10 seconds epochs)\n",
    "### does rem, 1, 2, 3, wake have any statistical differences, - median, mean of delta, alpha, beta, gamma etc (10 seconds epochs)\n",
    "### take out all wake ones - -1 and look at the means again\n",
    "### every second - then use rnn - 2560 samples - label it as stage of sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a74e1231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2665, 2, 8),\n",
       " array([[ 0.00000000e+00,  3.53298728e-01,  8.47159635e-02,\n",
       "          2.90772044e-01,  4.88784679e-02,  1.25810049e-01,\n",
       "          9.65247484e-02,  8.25273367e-11],\n",
       "        [-1.00000000e+00,  3.50104641e-01,  5.45749447e-02,\n",
       "          3.54590414e-01,  4.09202009e-02,  1.21198380e-01,\n",
       "          7.86114194e-02,  6.21006795e-11]]),\n",
       " array([[-1.00000000e+00,  3.50104641e-01,  5.45749447e-02,\n",
       "          3.54590414e-01,  4.09202009e-02,  1.21198380e-01,\n",
       "          7.86114194e-02,  6.21006795e-11],\n",
       "        [-1.00000000e+00,  2.47155461e-01,  6.64443417e-02,\n",
       "          4.99359931e-01,  2.79174666e-02,  9.32140987e-02,\n",
       "          6.59087010e-02,  6.41699998e-11]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X[0], X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b2d5939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2665,), np.int64(0), np.int64(0))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, y[0], y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0add34ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c02332ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class HypopneaDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)\n",
    "\n",
    "train_ds = HypopneaDataset(X_train, y_train)\n",
    "test_ds = HypopneaDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e19ca289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2665,), np.int64(0))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, y[0]  # (2, num_features)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d1b7851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2665, 2, 8),\n",
       " array([[ 0.00000000e+00,  3.53298728e-01,  8.47159635e-02,\n",
       "          2.90772044e-01,  4.88784679e-02,  1.25810049e-01,\n",
       "          9.65247484e-02,  8.25273367e-11],\n",
       "        [-1.00000000e+00,  3.50104641e-01,  5.45749447e-02,\n",
       "          3.54590414e-01,  4.09202009e-02,  1.21198380e-01,\n",
       "          7.86114194e-02,  6.21006795e-11]]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X[0]  # (2, num_features)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ffaf8a",
   "metadata": {},
   "source": [
    "```\n",
    "Input:     (batch_size, seq_len=2, input_size=8)\n",
    "             │\n",
    "             ▼\n",
    "         ┌─────────────┐\n",
    "         │   RNN Layer │\n",
    "         │  (8 → 32)   │\n",
    "         └─────────────┘\n",
    "             │\n",
    "   Output shape: (batch_size, seq_len=2, hidden_size=32)\n",
    "             │\n",
    "             ▼\n",
    "Take the last timestep output:\n",
    "    out[:, -1, :] → shape = (batch_size, hidden_size=32)\n",
    "             │\n",
    "             ▼\n",
    "     ┌────────────────────┐\n",
    "     │  Fully Connected   │\n",
    "     │   (Linear 32 → 4)  │\n",
    "     └────────────────────┘\n",
    "             │\n",
    "             ▼\n",
    "Final Output: (batch_size, num_classes=4)\n",
    "→ Apply CrossEntropyLoss for training\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5624663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)  # out: (batch, seq_len, hidden)\n",
    "        out = out[:, -1, :]   # take last timestep output\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = RNNClassifier(input_size=8, hidden_size=32, num_classes=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd58d3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 48.1950\n",
      "Epoch 2, Loss: 19.1318\n",
      "Epoch 3, Loss: 17.8343\n",
      "Epoch 4, Loss: 17.3154\n",
      "Epoch 5, Loss: 17.2825\n",
      "Epoch 6, Loss: 17.0805\n",
      "Epoch 7, Loss: 17.2770\n",
      "Epoch 8, Loss: 17.1630\n",
      "Epoch 9, Loss: 17.0212\n",
      "Epoch 10, Loss: 17.0836\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8e59af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 94.56%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a505dc6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
